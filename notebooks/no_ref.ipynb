{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from desci_sense.twitter import scrape_tweet\n",
    "\n",
    "from desci_sense.postprocessing.output_parsers import TagTypeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TWEET_W_REF = \"https://twitter.com/victorveitch/status/1722300572554969090\"\n",
    "TEST_TWEET_W_REF_2 = \"https://twitter.com/maksym_andr/status/1722235666724192688\"\n",
    "TEST_TWEET_WO_REF_1 = \"https://twitter.com/mpshanahan/status/1722283975450722407\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# based on ChatGPT and https://stackoverflow.com/a/6041965\n",
    "def extract_urls(text):\n",
    "    url_regex = r'((http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-]))'\n",
    "    res = re.findall(url_regex, text)\n",
    "    final_res = [r[0] for r in res]\n",
    "    return final_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CASES = [\n",
    "\n",
    "    (\"https://twitter.com/victorveitch/status/1722300572554969090\", True),\n",
    "    (\"https://twitter.com/maksym_andr/status/1722235666724192688\", True),\n",
    "    (\"https://twitter.com/mpshanahan/status/1722283975450722407\", False),\n",
    "    (\"https://twitter.com/victorveitch/status/1722303746397409698\", False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversationID': '1722283973433291133',\n",
       " 'date': 'Wed Nov 08 16:04:32 +0000 2023',\n",
       " 'date_epoch': 1699459472,\n",
       " 'hashtags': [],\n",
       " 'likes': 3,\n",
       " 'mediaURLs': [],\n",
       " 'media_extended': [],\n",
       " 'possibly_sensitive': False,\n",
       " 'qrtURL': None,\n",
       " 'replies': 2,\n",
       " 'retweets': 0,\n",
       " 'text': \"It's about how we can use the concept of role play to better understand large language models and dialogue agents, such as #ChatGPT and @Google's Bard. #AI\\n2/\",\n",
       " 'tweetID': '1722283975450722407',\n",
       " 'tweetURL': 'https://twitter.com/mpshanahan/status/1722283975450722407',\n",
       " 'user_name': 'Murray Shanahan',\n",
       " 'user_screen_name': 'mpshanahan'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = scrape_tweet(TEST_TWEET_WO_REF_1)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's about how we can use the concept of role play to better understand large language models and dialogue agents, such as #ChatGPT and @Google's Bard. #AI\n",
      "2/\n"
     ]
    }
   ],
   "source": [
    "print(tweet[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://t.co/8WXQVI4WBb']\n",
      "['https://arxiv.org/abs/2311.01906', 'https://t.co/PlPRQVL9yc']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for url, has_url in TEST_CASES:\n",
    "    tweet = scrape_tweet(url)\n",
    "    print(extract_urls(tweet[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/rkl25/dev/common_sense/desci-sense/notebooks/no_ref.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rkl25/dev/common_sense/desci-sense/notebooks/no_ref.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     full_url \u001b[39m=\u001b[39m short_url\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rkl25/dev/common_sense/desci-sense/notebooks/no_ref.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rkl25/dev/common_sense/desci-sense/notebooks/no_ref.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# replace by your error handling:\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rkl25/dev/common_sense/desci-sense/notebooks/no_ref.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39massert\u001b[39;00m(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Short URL for a Python Requests Tutorial\n",
    "short_url = 'https://t.co/8WXQVI4WBb'\n",
    "\n",
    "res = requests.head(short_url)\n",
    "if res.status_code == 303: # \"See Other\"\n",
    "    full_url = res.headers['location']\n",
    "elif res.status_code == 200: # \"OK\"\n",
    "    # let's conclude that short_url is already what we are looking for\n",
    "    full_url = short_url\n",
    "else:\n",
    "    # replace by your error handling:\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/victorveitch/status/1722300572554969090/photo/1'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "long_url = 'https://stackoverflow.com/questions/65097231/resolve-masked-shortened-url-twint-is-scraping-from-twitter'\n",
    "short_url = 'https://t.co/8WXQVI4WBb'\n",
    "\n",
    "resp = requests.head(short_url)\n",
    "resp.status_code\n",
    "true_url = resp.headers[\"Location\"]\n",
    "true_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.example.com', 'http://example.org', 'https://www.example.net']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_urls(text):\n",
    "    url_regex = r'https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+'\n",
    "    return re.findall(url_regex, text)\n",
    "\n",
    "# Example usage:\n",
    "text_with_urls = \"Here are some URLs: https://www.example.com, http://example.org, and https://www.example.net/path/to/page.html\"\n",
    "urls = extract_urls(text_with_urls)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/victorveitch/status/1722300572554969090\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def unshorten_url(url):\n",
    "    try:\n",
    "        response = requests.head(url, allow_redirects=True)\n",
    "        return response.url\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return url\n",
    "\n",
    "# Example usage:\n",
    "short_url = \"https://t.co/8WXQVI4WBb\"\n",
    "\n",
    "long__test_url = 'https://twitter.com/victorveitch/status/1722300572554969090'\n",
    "long_url = unshorten_url(long__test_url)\n",
    "print(long_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(text):\n",
    "    \"\"\" takes a string text as input and uses the regular expression pattern to find all \n",
    "    occurrences of URLs in the text. returns a list of all non-overlapping matches of the regular expression pattern in the string.\n",
    "    \"\"\"\n",
    "    url_regex = r'((http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-]))'\n",
    "    res = re.findall(url_regex, text)\n",
    "    final_res = [r[0] for r in res]\n",
    "    return final_res\n",
    "\n",
    "\n",
    "def unshorten_url(url):\n",
    "    try:\n",
    "        response = requests.head(url, allow_redirects=True)\n",
    "        return response.url\n",
    "    except requests.RequestException as e:\n",
    "        # return original url in case of errors\n",
    "        return url\n",
    "    \n",
    "\n",
    "def extract_and_expand_urls(text):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        text (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    expanded_urls = [unshorten_url(url) for url in extract_urls(text)]\n",
    "    return expanded_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://twitter.com/victorveitch/status/1722300572554969090/photo/1']\n",
      "['https://arxiv.org/abs/2311.01906', 'https://twitter.com/maksym_andr/status/1722235666724192688/photo/1']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for url, has_url in TEST_CASES:\n",
    "    tweet = scrape_tweet(url)\n",
    "    print(extract_and_expand_urls(tweet[\"text\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
