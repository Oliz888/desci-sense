{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env with api keys https://stackoverflow.com/a/54028874\n",
    "%load_ext dotenv\n",
    "%dotenv ../etc/config.env\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from twitter import scrape_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_TWEET = \"https://twitter.com/danwilliamsphil/status/1719436704602275858\"\n",
    "# TEST_TWEET = \"https://twitter.com/pwang/status/1719720728184910195\"\n",
    "TEST_TWEET = \"https://twitter.com/BlancheMinerva/status/1719714881081954409\"\n",
    "TEST_TWEET = \"https://twitter.com/sucholutsky/status/1719725087681569189\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversationID': '1719714878263349725',\n",
       " 'date': 'Wed Nov 01 13:55:53 +0000 2023',\n",
       " 'date_epoch': 1698846953,\n",
       " 'hashtags': [],\n",
       " 'likes': 2,\n",
       " 'mediaURLs': [],\n",
       " 'media_extended': [],\n",
       " 'possibly_sensitive': False,\n",
       " 'qrtURL': None,\n",
       " 'replies': 1,\n",
       " 'retweets': 0,\n",
       " 'text': 'There are hundreds of researches around the world who are doing safety-critical research precisely because organizations like @AiEleuther @AIatMeta @TIIuae and @MosaicML release models for people to download. Every time I go to an AI conference I meet a dozen such people.',\n",
       " 'tweetID': '1719714881081954409',\n",
       " 'tweetURL': 'https://twitter.com/BlancheMinerva/status/1719714881081954409',\n",
       " 'user_name': 'Stella Biderman',\n",
       " 'user_screen_name': 'BlancheMinerva'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = scrape_tweet(TEST_TWEET)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! headers is not default parameter.\n",
      "                    headers was transferred to model_kwargs.\n",
      "                    Please confirm that headers is what you intended.\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "\n",
    "OPENROUTER_API_BASE = \"https://openrouter.ai/api/v1\"\n",
    "# openai.api_key = os.environ[\"OPENROUTER_API_KEY\"]\n",
    "\n",
    "model_name = \"mistralai/mistral-7b-instruct\" # currently free on OpenRouter (https://openrouter.ai/docs#models)\n",
    "# model_name = \"openai/gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "        model=model_name, \n",
    "        temperature=0.7,\n",
    "        openai_api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "        openai_api_base=OPENROUTER_API_BASE,\n",
    "        headers={\"HTTP-Referer\": os.environ[\"OPENROUTER_REFERRER\"]}, # To identify your app. Can be set to e.g. http://localhost:3000 for testing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning steps:\n",
      "1. The post mentions \"hundreds of researches\" which suggests a review of a research paper or article.\n",
      "2. The post also mentions \"organizations like @AiEleuther @AIatMeta @TIIuae and @MosaicML\" which suggests a review of a set of organizations or their activities.\n",
      "3. However, the post does not explicitly mention any particular reference, so the <review> tag may not be suitable.\n",
      "4. The post mentions \"safety-critical research\" which could potentially be a review of a specific topic or field.\n",
      "5. The post also mentions \"people\" which suggests a review of a human experience or perspective.\n",
      "\n",
      "Final answer: <review>, <other>\n"
     ]
    }
   ],
   "source": [
    "# based on https://python.langchain.com/docs/get_started/quickstart#prompttemplate--llm--outputparser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "    \n",
    "class StripOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip()\n",
    "\n",
    "template = \"\"\"You are an expert annotator who tags social media posts related to academic research, according to a predefined set of tags. \n",
    "The available tag types are:\n",
    "<announce>: this post contains an announcement of new research, likely by the authors. The research may be a paper, dataset or other type of research output.\n",
    "<review>: this post contains a review of another reference, such as a book, article or movie. The review could be positive or negative.\n",
    "<other>: use this if no other tag is suitable. If you tag a post with <Other>, no other tag should be assigned to the post.\n",
    "\n",
    "A user will pass in a post, and you should think step by step, before returning a list of comma separated tags that best match the post.\n",
    "\n",
    "Your final answer should be structured as follows:\n",
    "# Reasoning steps: (your reasoning steps. For each tag you choose, explain why you chose it.)\n",
    "# Final answer: (the final list of tags, based on the reasoning steps)\n",
    "\n",
    "Remember:\n",
    "The final answer should ONLY include tags from the list above, nothing more.\n",
    "If the <other> tag is included in the answer, no other tag should be included!\"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "# chain = chat_prompt | chat | CommaSeparatedListOutputParser()\n",
    "chain = chat_prompt | chat | StripOutputParser()\n",
    "answer = chain.invoke({\"text\": tweet[\"text\"]})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create OpenAI model\n",
    "\n",
    "This works, what about a free one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.schema import (\n",
    "#     HumanMessage,\n",
    "# )\n",
    "\n",
    "# import openai\n",
    "# import os\n",
    "\n",
    "# OPENROUTER_API_BASE = \"https://openrouter.ai/api/v1\"\n",
    "# openai.api_key = os.environ[\"OPENROUTER_API_KEY\"]\n",
    "\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#         temperature=0.7,\n",
    "#         openai_api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "#         openai_api_base=OPENROUTER_API_BASE,\n",
    "#         headers={\"HTTP-Referer\": os.environ[\"OPENROUTER_REFERRER\"]}, \n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
