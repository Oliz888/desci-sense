{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env with api keys https://stackoverflow.com/a/54028874\n",
    "%load_ext dotenv\n",
    "%dotenv ../etc/config.env\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from twitter import scrape_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TWEET_1 = \"https://twitter.com/danwilliamsphil/status/1719436704602275858\"\n",
    "TEST_TWEET_2 = \"https://twitter.com/pwang/status/1719720728184910195\"\n",
    "TEST_TWEET_3 = \"https://twitter.com/BlancheMinerva/status/1719714881081954409\"\n",
    "TEST_TWEET_4 = \"https://twitter.com/sucholutsky/status/1719725087681569189\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversationID': '1719725087681569189',\n",
       " 'date': 'Wed Nov 01 14:36:26 +0000 2023',\n",
       " 'date_epoch': 1698849386,\n",
       " 'hashtags': ['NeurIPS2023'],\n",
       " 'likes': 4,\n",
       " 'mediaURLs': ['https://pbs.twimg.com/media/F92w1rQXUAAvfHw.jpg'],\n",
       " 'media_extended': [{'altText': None,\n",
       "   'size': {'height': 760, 'width': 1247},\n",
       "   'thumbnail_url': 'https://pbs.twimg.com/media/F92w1rQXUAAvfHw.jpg',\n",
       "   'type': 'image',\n",
       "   'url': 'https://pbs.twimg.com/media/F92w1rQXUAAvfHw.jpg'}],\n",
       " 'possibly_sensitive': False,\n",
       " 'qrtURL': None,\n",
       " 'replies': 1,\n",
       " 'retweets': 3,\n",
       " 'text': \"ðŸ§µ Excited to share another new paper with @cocosci_lab, accepted as a spotlight at #NeurIPS2023! ðŸŽ‰ We delve into the intriguing intersection of AI and human cognition, exploring how alignment with human representations impacts few-shot learning tasks.ðŸ§ ðŸ¤–ðŸŽ“ Let's unpack this!ðŸ‘‡ https://t.co/ayvpHIw76s\",\n",
       " 'tweetID': '1719725087681569189',\n",
       " 'tweetURL': 'https://twitter.com/sucholutsky/status/1719725087681569189',\n",
       " 'user_name': 'Ilia Sucholutsky',\n",
       " 'user_screen_name': 'sucholutsky'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = scrape_tweet(TEST_TWEET_4)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! headers is not default parameter.\n",
      "                    headers was transferred to model_kwargs.\n",
      "                    Please confirm that headers is what you intended.\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "\n",
    "OPENROUTER_API_BASE = \"https://openrouter.ai/api/v1\"\n",
    "# openai.api_key = os.environ[\"OPENROUTER_API_KEY\"]\n",
    "\n",
    "model_name = \"mistralai/mistral-7b-instruct\" # currently free on OpenRouter (https://openrouter.ai/docs#models)\n",
    "# model_name = \"openai/gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "        model=model_name, \n",
    "        temperature=0.7,\n",
    "        openai_api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "        openai_api_base=OPENROUTER_API_BASE,\n",
    "        headers={\"HTTP-Referer\": os.environ[\"OPENROUTER_REFERRER\"]}, # To identify your app. Can be set to e.g. http://localhost:3000 for testing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Reasoning steps:\n",
      "\n",
      "1. The post is about a new research paper that has been accepted for presentation at NeurIPS 2023.\n",
      "2. The paper explores the intersection of AI and human cognition.\n",
      "3. The authors are excited to share the paper with the community.\n",
      "4. No explicit tag is mentioned in the post, so it falls under the <other> tag.\n",
      "\n",
      "# Final answer: Other\n"
     ]
    }
   ],
   "source": [
    "# based on https://python.langchain.com/docs/get_started/quickstart#prompttemplate--llm--outputparser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "    \n",
    "class StripOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip()\n",
    "\n",
    "template = \"\"\"You are an expert annotator who tags social media posts related to academic research, according to a predefined set of tags. \n",
    "The available tag types are:\n",
    "<announce>: this post contains an announcement of new research, likely by the authors. The research may be a paper, dataset or other type of research output that the authors are announcing publicly.\n",
    "<review>: this post contains a review of another reference, such as a book, article or movie. The review could be positive or negative.\n",
    "<other>: use this if no other tag is suitable. If you tag a post with <Other>, no other tag should be assigned to the post.\n",
    "\n",
    "A user will pass in a post, and you should think step by step, before returning a list of comma separated tags that best match the post.\n",
    "\n",
    "Your final answer should be structured as follows:\n",
    "# Reasoning steps: (your reasoning steps. For each tag you choose, explain why you chose it.)\n",
    "# Final answer: (the final list of tags, based on the reasoning steps)\n",
    "\n",
    "Remember:\n",
    "The final answer should ONLY include tags from the list above, nothing more. Do not make up any new tags that are not in the list above!\n",
    "If the <other> tag is included in the answer, no other tag should be included!\"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "# chain = chat_prompt | chat | CommaSeparatedListOutputParser()\n",
    "chain = chat_prompt | chat | StripOutputParser()\n",
    "answer = chain.invoke({\"text\": tweet[\"text\"]})\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
